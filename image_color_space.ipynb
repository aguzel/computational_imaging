{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_color_space.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMYkcy0/eZJ4mxI2+9vO0Dp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguzel/computational_imaging/blob/main/image_color_space.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np_cpu\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "\n",
        "from torchvision import transforms\n",
        "\n",
        "\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "6Ih7Z2j7oVk1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "iToEIzXAkpQ8"
      },
      "outputs": [],
      "source": [
        "class image_color_space():\n",
        "    \"\"\"\n",
        "    A class for manipulating color space of an image.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self,image_location):\n",
        "      self.image_location = image_location\n",
        "      \n",
        "    \n",
        "\n",
        "    def load_image(self):\n",
        "      \"\"\"\n",
        "      Definition to load an image from a given location as a Numpy array.\n",
        "      Parameters\n",
        "      ----------\n",
        "      fn           : str\n",
        "                     Filename.\n",
        "      Returns\n",
        "      ----------\n",
        "      image        :  NCHW\n",
        "                      Image loaded as a Numpy array.\n",
        "      \"\"\"\n",
        "      image = Image.open(self.image_location)\n",
        "      image = np_cpu.array(image)\n",
        "      image = torch.from_numpy(image)\n",
        "      image = torch.swapaxes(image,0,2)\n",
        "      image = image.unsqueeze(0)\n",
        "      return image\n",
        "    \n",
        "    def rgb_2_ycrcb(self,image):\n",
        "        \"\"\"\n",
        "        Converts an image from RGB colourspace to YCrCb colourspace.\n",
        "        Parameters\n",
        "        ----------\n",
        "        image   : torch.tensor\n",
        "                    Input image. Should be an RGB floating-point image with values in the range [0, 1]\n",
        "                    Should be in NCHW format.\n",
        "        Returns\n",
        "        -------\n",
        "        ycrcb   : torch.tensor\n",
        "                    Image converted to YCrCb colourspace.\n",
        "        \"\"\"\n",
        "        ycrcb = torch.zeros(image.size()).to(image.device)\n",
        "        ycrcb[:, 0, :, :] = 0.299 * image[:, 0, :, :] + 0.587 * \\\n",
        "            image[:, 1, :, :] + 0.114 * image[:, 2, :, :]\n",
        "        ycrcb[:, 1, :, :] = 0.5 + 0.713 * (image[:, 0, :, :] - ycrcb[:, 0, :, :])\n",
        "        ycrcb[:, 2, :, :] = 0.5 + 0.564 * (image[:, 2, :, :] - ycrcb[:, 0, :, :])\n",
        "        return ycrcb\n",
        "\n",
        "    def ycrcb_2_rgb(self,image):\n",
        "        \"\"\"\n",
        "        Converts an image from YCrCb colourspace to RGB colourspace.\n",
        "        Parameters\n",
        "        ----------\n",
        "        image   : torch.tensor\n",
        "                    Input image. Should be a YCrCb floating-point image with values in the range [0, 1]\n",
        "                    Should be in NCHW format.\n",
        "        Returns\n",
        "        -------\n",
        "        rgb     : torch.tensor\n",
        "                    Image converted to RGB colourspace.\n",
        "        \"\"\"\n",
        "        rgb = torch.zeros(image.size(), device=image.device)\n",
        "        rgb[:, 0, :, :] = image[:, 0, :, :] + 1.403 * (image[:, 1, :, :] - 0.5)\n",
        "        rgb[:, 1, :, :] = image[:, 0, :, :] - 0.714 * \\\n",
        "            (image[:, 1, :, :] - 0.5) - 0.344 * (image[:, 2, :, :] - 0.5)\n",
        "        rgb[:, 2, :, :] = image[:, 0, :, :] + 1.773 * (image[:, 2, :, :] - 0.5)\n",
        "        return rgb\n",
        "\n",
        "    def rgb_2_hsv(self,image,eps):\n",
        "        image = image / 255.0\n",
        "        hue = torch.Tensor(image.shape[0], image.shape[2], image.shape[3]).to(image.device)\n",
        "\n",
        "        hue[ image[:,2]==image.max(1)[0] ] = 4.0 + ( (image[:,0]-image[:,1]) / ( image.max(1)[0] - image.min(1)[0] + eps) ) [ image[:,2]==image.max(1)[0] ]\n",
        "        hue[ image[:,1]==image.max(1)[0] ] = 2.0 + ( (image[:,2]-image[:,0]) / ( image.max(1)[0] - image.min(1)[0] + eps) ) [ image[:,1]==image.max(1)[0] ]\n",
        "        hue[ image[:,0]==image.max(1)[0] ] = (0.0 + ( (image[:,1]-image[:,2]) / ( image.max(1)[0] - image.min(1)[0] + eps) ) [ image[:,0]==image.max(1)[0] ]) % 6\n",
        "\n",
        "        hue[image.min(1)[0]==image.max(1)[0]] = 0.0\n",
        "        hue = hue/6\n",
        "\n",
        "        saturation = ( image.max(1)[0] - image.min(1)[0] ) / ( image.max(1)[0] + eps )\n",
        "        saturation[ image.max(1)[0]==0 ] = 0\n",
        "\n",
        "        value = image.max(1)[0]\n",
        "        hue = hue.unsqueeze(1)\n",
        "        saturation = saturation.unsqueeze(1)\n",
        "        value = value.unsqueeze(1)\n",
        "        hsv = torch.cat([hue,saturation,value], dim =1)\n",
        "        return hsv  \n",
        "\n",
        "\n",
        "    def hsv_2_rgb(self,hsv_image):\n",
        "\n",
        "        h = hsv_image[:,0,:,:]\n",
        "        s = hsv_image[:,1,:,:]\n",
        "        v = hsv_image[:,2,:,:]\n",
        "        \n",
        "        h = h%1\n",
        "        s = torch.clamp(s,0,1)\n",
        "        v = torch.clamp(v,0,1)\n",
        "\n",
        "        r = torch.zeros_like(h)\n",
        "        g = torch.zeros_like(h)\n",
        "        b = torch.zeros_like(h)\n",
        "\n",
        "        hi = torch.floor(h * 6)\n",
        "        f = h * 6 - hi\n",
        "        p = v * (1 - s)\n",
        "        q = v * (1 - (f * s))\n",
        "        t = v * (1 - ((1 - f) * s))\n",
        "\n",
        "        hi0 = hi == 0\n",
        "        hi1 = hi == 1\n",
        "        hi2 = hi == 2\n",
        "        hi3 = hi == 3\n",
        "        hi4 = hi == 4 \n",
        "        hi5 = hi == 5\n",
        "\n",
        "        r[hi0] = v[hi0]\n",
        "        g[hi0] = t[hi0]\n",
        "        b[hi0] = p[hi0]\n",
        "\n",
        "        r[hi1] = q[hi1]\n",
        "        g[hi1] = v[hi1]\n",
        "        b[hi1] = p[hi1]\n",
        "        \n",
        "        r[hi2] = p[hi2]\n",
        "        g[hi2] = v[hi2]\n",
        "        b[hi2] = t[hi2]\n",
        "\n",
        "        r[hi3] = p[hi3]\n",
        "        g[hi3] = q[hi3]\n",
        "        b[hi3] = v[hi3]\n",
        "\n",
        "        r[hi4] = t[hi4]\n",
        "        g[hi4] = p[hi4]\n",
        "        b[hi4] = v[hi4]\n",
        "\n",
        "        r[hi5] = v[hi5]\n",
        "        g[hi5] = p[hi5]\n",
        "        b[hi5] = q[hi5]\n",
        "\n",
        "        r = r.unsqueeze(1)\n",
        "        g = g.unsqueeze(1)\n",
        "        b = b.unsqueeze(1)\n",
        "\n",
        "        rgb_image = torch.cat([r,g,b], dim = 1)\n",
        "        return rgb_image\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "color_space = image_color_space('/content/parrot.png')"
      ],
      "metadata": {
        "id": "-fsTeMAJoTV1"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image = color_space.load_image()"
      ],
      "metadata": {
        "id": "B5dfBeYEpCTz"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "image"
      ],
      "metadata": {
        "id": "lYAASpI45Kpf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hsv_tensor_image = color_space.rgb_2_hsv(image,1e-8)"
      ],
      "metadata": {
        "id": "VedL4Jx3rYNk"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_image = color_space.hsv_2_rgb(hsv_tensor_image)"
      ],
      "metadata": {
        "id": "uR3OMgChze39"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_image"
      ],
      "metadata": {
        "id": "C_qq6wESzp-c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rgb_image.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdPoAIuS1mD_",
        "outputId": "b4412f79-df33-48be-a442-844d033b1879"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 3, 1001, 1001])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "numpy_image = rgb_image.cpu().detach().numpy()\n",
        "numpy_image = numpy_image.squeeze(0)\n",
        "numpy_image = numpy_image.swapaxes(0,2)\n",
        "plt.imshow(numpy_image)"
      ],
      "metadata": {
        "id": "p5FfxeEhp7qw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.colors as mcolors"
      ],
      "metadata": {
        "id": "6LJ4Gmej2ep2"
      },
      "execution_count": 59,
      "outputs": []
    }
  ]
}